{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "255f24a5",
   "metadata": {},
   "source": [
    "# Main "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef47039",
   "metadata": {},
   "source": [
    "## Check Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053ffa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers_functions.setup import *\n",
    "\n",
    "path_archive = \"archive\"\n",
    "\n",
    "path_train_val_list = \"archive/train_val_list_NIH.txt\"\n",
    "path_test_list = \"archive/test_list_NIH.txt\"\n",
    "\n",
    "path_all_data_csv = \"archive/Data_Entry_2017.csv\"\n",
    "\n",
    "path_folder_images = \"archive/images-224/images-224\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4b7765",
   "metadata": {},
   "source": [
    "### Check structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f2d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "path = path_archive\n",
    "print(json.dumps(list_tree(path, max_depth=1), indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cf30a3",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d8a9b8",
   "metadata": {},
   "source": [
    "### Create class-label linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb8c216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers_functions.multi_hot import *\n",
    "\n",
    "class_label_str_to_idx, class_label_idx_to_str = create_class_mappings(path_all_data_csv)\n",
    "\n",
    "print(class_label_str_to_idx)\n",
    "print(class_label_idx_to_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab42f799",
   "metadata": {},
   "source": [
    "### Multi-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ed7c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume class_to_idx and idx_to_class are already created\n",
    "image_to_multihot = create_image_multihot_mapping_from_dicts(path_all_data_csv, class_label_str_to_idx)\n",
    "\n",
    "# Check the first image mapping\n",
    "first_image = list(image_to_multihot.keys())[0]\n",
    "print(first_image, image_to_multihot[first_image])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b13cb68",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "#### Make a Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6955273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MedicalImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for medical images with precomputed multi-hot labels.\n",
    "\n",
    "    Each sample returns:\n",
    "        - image tensor\n",
    "        - multi-hot label vector\n",
    "        - image file name\n",
    "    \"\"\"\n",
    "    def __init__(self, files_list_dir: str, img_dir: str, image_to_multihot: dict, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            files_list_dir (str): Path to a .txt file with each row being an image name.\n",
    "            img_dir (str): Directory containing the images.\n",
    "            image_to_multihot (dict): Precomputed dictionary mapping image name â†’ multi-hot vector.\n",
    "            transform (callable, optional): Optional transform to apply to images.\n",
    "        \"\"\"\n",
    "        # Load image names from txt\n",
    "        with open(files_list_dir, \"r\") as f:\n",
    "            self.image_names = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "        self.image_to_multihot = image_to_multihot\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Ensure no infinite loop\n",
    "        if idx >= 2 * len(self):\n",
    "            raise FileNotFoundError(f\"No valid images.\")\n",
    "\n",
    "        img_name = self.image_names[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "\n",
    "        # Skip missing images\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"Warning: Image file '{img_path}' not found. Skipping to next index.\")\n",
    "            return self.__getitem__((idx + 1) % len(self))  # wrap around if at end\n",
    "\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            # Default conversion to tensor\n",
    "            image = torch.from_numpy(np.array(image)).permute(2,0,1).float() / 255.0\n",
    "\n",
    "        # Get multi-hot vector from precomputed dictionary\n",
    "        multi_hot = torch.from_numpy(\n",
    "            self.image_to_multihot.get(\n",
    "                img_name,\n",
    "                np.zeros(len(next(iter(self.image_to_multihot.values()))),\n",
    "                dtype=np.float32)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return image, multi_hot, img_name\n",
    "\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "dataset = MedicalImageDataset(path_train_val_list, path_folder_images, image_to_multihot)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Get the first batch\n",
    "imgs, multi_hot, names = next(iter(loader))\n",
    "\n",
    "print(\"Image batch shape:\", imgs.shape)\n",
    "print(\"Label batch shape:\", multi_hot.shape)\n",
    "print(\"First image name:\", names[0])\n",
    "print(\"First label vector:\", multi_hot[0])\n",
    "\n",
    "# Display the first image in the batch\n",
    "plt.imshow(imgs[0].permute(1, 2, 0))\n",
    "plt.title(f\"Image: {names[0]}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7b210c",
   "metadata": {},
   "source": [
    "#### Create CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ca3484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.models import *\n",
    "\n",
    "model_name = \"All\"\n",
    "model = models(model_name)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75b0d36",
   "metadata": {},
   "source": [
    "#### Train the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfcaf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.train import *\n",
    "from models.val import *\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Train Parameters\n",
    "epochs = 10\n",
    "val_every = 5\n",
    "batch_size = 16\n",
    "save = False\n",
    "save_every = 1\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Split the dataset into train and val\n",
    "val_ratio = 0.2\n",
    "total_size = len(dataset)\n",
    "val_size = int(total_size * val_ratio)\n",
    "train_size = total_size - val_size\n",
    "torch.manual_seed(42) # Set seed for reproducibility\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "\n",
    "\n",
    "# Train model\n",
    "for epoch in range(0, epochs, val_every):\n",
    "    train(\n",
    "        model_name,\n",
    "        model, \n",
    "        optimizer,\n",
    "        train_dataset, start_epoch=epoch, end_epoch=min(epoch+val_every, epochs),\n",
    "        batch_size=batch_size, device=device, \n",
    "        save=save, save_every=save_every, checkpoint_dir=f\"checkpoints/{model_name}\"\n",
    "    )\n",
    "    \n",
    "    val(model_name, \n",
    "        model, \n",
    "        val_dataset, epoch=epoch+val_every, \n",
    "        batch_size=batch_size, device=device\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aab63a",
   "metadata": {},
   "source": [
    "#### Classifier Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb156ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset and DataLoader\n",
    "test_dataset = MedicalImageDataset(path_test_list, path_folder_images, image_to_multihot)\n",
    "\n",
    "test_loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Get the first batch\n",
    "imgs, multi_hot, names = next(iter(test_loader))\n",
    "\n",
    "print(\"Image batch shape:\", imgs.shape)\n",
    "print(\"Label batch shape:\", multi_hot.shape)\n",
    "print(\"First image name:\", names[0])\n",
    "print(\"First label vector:\", multi_hot[0])\n",
    "\n",
    "# Display the first image in the batch\n",
    "plt.imshow(imgs[0].permute(1, 2, 0))\n",
    "plt.title(f\"Image: {names[0]}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad1f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers_functions.metrics import *\n",
    "from models.pred import *\n",
    "\n",
    "\n",
    "df = evaluate(\n",
    "    model_name=model_name, \n",
    "    model=model,\n",
    "    pred=pred, \n",
    "    dataset=test_dataset)\n",
    "\n",
    "print(json.dumps(df.to_dict(), indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
